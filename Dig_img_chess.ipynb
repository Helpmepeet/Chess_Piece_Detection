{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown --remaining-ok 1TM_VQzVYkWXC0ApXUcsyFYpOJQPIrxqe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwF0JOoCeXf",
        "outputId": "86b81cbf-20eb-4ceb-e541-02719d717959"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TM_VQzVYkWXC0ApXUcsyFYpOJQPIrxqe\n",
            "To: /content/yolo8-20epoch.pt\n",
            "100% 6.25M/6.25M [00:00<00:00, 25.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWcnpIxVzxC8",
        "outputId": "68ebe697-81e9-4e3e-b132-f505a09241a1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Building wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=5e45882027d314aa69de23572e02403e6ae9d78d6476d10d398fdbaf51a4e110\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: chess, python-chess\n",
            "Successfully installed chess-1.11.2 python-chess-1.999\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.112-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.112-py3-none-any.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.112 ultralytics-thop-2.0.14\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.61-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.61\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install python-chess\n",
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import everything"
      ],
      "metadata": {
        "id": "mbonRLB0V_0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1tSdqCbz3W1",
        "outputId": "40d57e83-3d74-4ab6-8bf3-d465f179a0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.112 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.2/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import chess\n",
        "import chess.svg\n",
        "import chess.pgn\n",
        "from IPython.display import SVG, display\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from IPython.display import Video\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from roboflow import Roboflow\n",
        "import warnings\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "ultralytics.checks()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD MODEL"
      ],
      "metadata": {
        "id": "UiKoGUBGvrG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chess_model = YOLO(\"/content/drive/MyDrive/weights/chess/chessPieceV3.pt\")\n",
        "corner_det = YOLO(\"/content/drive/MyDrive/weights/chess/corner_det.pt\")\n",
        "chess_model = YOLO(\"/content/yolo8-20epoch.pt\")\n",
        "# print(chess_model1.names)\n",
        "# print(chess_model2.names)"
      ],
      "metadata": {
        "id": "raeAz3ByvtE9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNPM8yrhJrru"
      },
      "source": [
        "## LOAD Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZfkncxmX0FA_"
      },
      "outputs": [],
      "source": [
        "# rf = Roboflow(api_key=\"ozCcRqAwKW37LPNL89gN\")\n",
        "# project = rf.workspace(\"digimg\").project(\"chess-piece-lwscg\")\n",
        "# version = project.version(1)\n",
        "# dataset = version.download(\"yolov11\")\n",
        "\n",
        "\n",
        "# rf = Roboflow(api_key=\"ozCcRqAwKW37LPNL89gN\")\n",
        "# project = rf.workspace(\"digimg\").project(\"chess-piece-lwscg\")\n",
        "# version = project.version(2)\n",
        "# dataset = version.download(\"yolov11\")\n",
        "\n",
        "\n",
        "# train_paths = [os.path.join(\"/content/chess-piece--2/train/images\", f) for f in os.listdir(\"/content/chess-piece--2/train/images\")]\n",
        "# valid_paths = [os.path.join(\"/content/chess-piece--2/valid/images\", f) for f in os.listdir(\"/content/chess-piece--2/valid/images\")]\n",
        "\n",
        "\n",
        "def get_random_path(paths):\n",
        "    return random.choice(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "7Bzm9skRAKdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chess_model.names\n",
        "# chess_model.train(data=\"/content/chess-piece--2/data.yaml\", epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq88C6yCAQT0",
        "outputId": "5ce04458-3ee4-48ec-898a-aa2543d74bad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'black-bishop',\n",
              " 1: 'black-king',\n",
              " 2: 'black-knight',\n",
              " 3: 'black-pawn',\n",
              " 4: 'black-queen',\n",
              " 5: 'black-rook',\n",
              " 6: 'white-bishop',\n",
              " 7: 'white-king',\n",
              " 8: 'white-knight',\n",
              " 9: 'white-pawn',\n",
              " 10: 'white-queen',\n",
              " 11: 'white-rook'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFDa0FqYMyBG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIND BOARD CORNER AND REMOVE DUPLICATE CORNER\n"
      ],
      "metadata": {
        "id": "jSEwUpNuIkvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def find_corners(img_path, plot=False):\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    detect_res = corner_det.predict(img_path)\n",
        "    if plot:\n",
        "        for box in detect_res[0].boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box)  # Convert coordinates to integers\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw rectangle\n",
        "        # Display image\n",
        "        # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        # plt.show()\n",
        "\n",
        "    return detect_res\n",
        "\n",
        "def get_corners(detection_result):\n",
        "\n",
        "    corners = []\n",
        "    for box in detection_result[0].boxes.xyxy:\n",
        "        x1, y1, x2, y2 = map(int, box)  # Convert coordinates to integers\n",
        "        corners.append(((x1, y1), (x2, y2)))\n",
        "    return corners\n",
        "\n",
        "def remove_close_corners(corners, threshold=100, print_res=False):\n",
        "\n",
        "    unique_corners = []\n",
        "    if print_res:\n",
        "        print(\"before remove =\", len(corners))\n",
        "    for corner in corners:\n",
        "        if not is_corner_in_list(corner, unique_corners, threshold):\n",
        "            unique_corners.append(corner)\n",
        "    if print_res:\n",
        "        print(\"after remove =\", len(unique_corners))\n",
        "    return unique_corners\n",
        "\n",
        "def change_to_points(corners):\n",
        "\n",
        "    points = []\n",
        "    for corner in corners:\n",
        "        centerX = (corner[0][0] + corner[1][0]) / 2\n",
        "        centerY = (corner[0][1] + corner[1][1]) / 2\n",
        "        points.append((centerX, centerY))\n",
        "    return np.array(points, dtype=\"float32\")\n",
        "\n",
        "def is_corner_in_list(corner, unique_corners, threshold=100):\n",
        "\n",
        "    for t in unique_corners:\n",
        "        if is_corners_close(corner, t, threshold):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def is_corners_close(corner1, corner2, threshold=100):\n",
        "\n",
        "    center1 = ((corner1[0][0] + corner1[1][0]) / 2, (corner1[0][1] + corner1[1][1]) / 2)\n",
        "    center2 = ((corner2[0][0] + corner2[1][0]) / 2, (corner2[0][1] + corner2[1][1]) / 2)\n",
        "    return abs(center1[0] - center2[0]) < threshold and abs(center1[1] - center2[1]) < threshold\n",
        "\n",
        "def order_points(points):\n",
        "\n",
        "    points = np.array(points)\n",
        "\n",
        "    x_sorted = points[np.argsort(points[:, 0]), :]\n",
        "\n",
        "    left_pts = x_sorted[:2]\n",
        "    right_pts = x_sorted[2:]\n",
        "\n",
        "    top_left = left_pts[np.argmin(left_pts[:, 1])]\n",
        "    bottom_left = left_pts[np.argmax(left_pts[:, 1])]\n",
        "    top_right = right_pts[np.argmin(right_pts[:, 1])]\n",
        "    bottom_right = right_pts[np.argmax(right_pts[:, 1])]\n",
        "\n",
        "    return np.array([top_left, top_right, bottom_right, bottom_left], dtype=\"float32\")\n",
        "\n",
        "def perspective_transform(img_path, corner_detector=corner_det, output_size=(640, 640), plot=False, expand=0):\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    src_points = get_src_points(img_path, corner_detector)\n",
        "    dst_points = np.array([[0, 0], [output_size[0], 0], [output_size[0], output_size[1]], [0, output_size[1]]], dtype=\"float32\")\n",
        "\n",
        "    if expand == 0:\n",
        "        matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "        warped = cv2.warpPerspective(img, matrix, output_size)\n",
        "\n",
        "        # if plot:\n",
        "        #     plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))\n",
        "        #     plt.show()\n",
        "        return warped\n",
        "\n",
        "\n",
        "\n",
        "def get_src_points(img_path, corner_detector=corner_det):\n",
        "    return np.array(order_points(change_to_points(remove_close_corners(get_corners(find_corners(img_path, corner_detector))))), dtype=\"float32\")\n",
        "\n",
        "def get_transformed_positions_and_classes(img_path, dst_points = np.array([[0, 0], [640, 0], [640, 640], [0, 640]], dtype=\"float32\"), board_pos=True):\n",
        "    pos_and_cls = get_positions_and_classes(img_path)\n",
        "    src_points = get_src_points(img_path)\n",
        "    ret_list = []\n",
        "    positions = []\n",
        "    for dct in pos_and_cls:\n",
        "        positions.append(dct[\"position\"])\n",
        "    # Convert the points to the required shape (N, 1, 2)\n",
        "    points_array = np.array(positions, dtype=\"float32\").reshape(-1, 1, 2)\n",
        "\n",
        "    # Calculate the perspective transformation matrix\n",
        "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "\n",
        "    # Apply the transformation\n",
        "    transformed_points = cv2.perspectiveTransform(points_array, matrix).reshape(-1, 2)\n",
        "    if board_pos:\n",
        "        for idx,p in enumerate(transformed_points):\n",
        "            p = p.tolist()\n",
        "            pos = get_board_pos(p[0], p[1])\n",
        "            ret_list.append({\"position\":pos, \"class_name\": pos_and_cls[idx][\"class_name\"]})\n",
        "        return ret_list\n",
        "    else:\n",
        "        for idx,p in enumerate(transformed_points):\n",
        "            ret_list.append({\"position\":p.tolist(), \"class_name\": pos_and_cls[idx][\"class_name\"]})\n",
        "        return ret_list\n",
        "\n",
        "# tmp_point = get_src_points(get_random_path(train_paths), corner_det)\n",
        "# get_transformed_positions([[0, 0], [100, 100]], tmp_point)"
      ],
      "metadata": {
        "id": "IRcWpP4fkoSv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Load the image\n",
        "# img_path = \"/content/chess-piece--1/train/images/1595777dfa66e954ae23655743e24809_jpg.rf.67bcd5b5d5605b3c92ab388c80e57b62.jpg\"\n",
        "# img = cv2.imread(img_path)\n",
        "\n",
        "# # Define the point to plot\n",
        "# point = (200, 100)  # (x, y)\n",
        "\n",
        "# # Draw a red dot on the image\n",
        "# img_with_dot = img.copy()  # Create a copy to avoid altering the original\n",
        "# cv2.circle(img_with_dot, point, radius=5, color=(0, 0, 255), thickness=-1)  # Red dot\n",
        "\n",
        "# # Display the image with the red dot\n",
        "# plt.imshow(cv2.cvtColor(img_with_dot, cv2.COLOR_BGR2RGB))\n",
        "# plt.title(\"Image with Red Dot\")\n",
        "# plt.show()\n",
        "\n",
        "# new_point = get_transformed_positions(point, get_src_points(img_path, corner_det))[0][0]\n",
        "# new_point = (int(new_point[0]), int(new_point[1]))\n",
        "# print(new_point)\n",
        "# warped = perspective_transform(img_path, corner_det, output_size=(640, 640), plot=False)\n",
        "# warped_img_with_dot = warped.copy()  # Create a copy to avoid altering the original\n",
        "# cv2.circle(warped_img_with_dot, new_point, radius=5, color=(0, 0, 255), thickness=-1)  # Red dot\n",
        "\n",
        "# # Display the image with the red dot\n",
        "# plt.imshow(cv2.cvtColor(warped_img_with_dot, cv2.COLOR_BGR2RGB))\n",
        "# plt.title(\"Image with Red Dot\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "INdXLVFn6za8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_path = \"/content/chess-piece--2/train/images/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.ce552028199c409d44fcbd51d96ec3a7.jpg\"\n",
        "# get_detect_res(img_path, plot=True)\n",
        "# find_corners(img_path, corner_det, plot=True)\n",
        "# mark_red_dots(img_path)"
      ],
      "metadata": {
        "id": "H4Ve6mFNnpMB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_detect_res(img_path, model=chess_model, plot=False):\n",
        "    result = model.predict(img_path)\n",
        "    if plot:\n",
        "        img = result[0].plot()\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_positions_and_classes(img_path, method=\"default\"):\n",
        "    \"\"\"\n",
        "    Extract positions and their associated classes from detection results.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): Path to the image.\n",
        "        method (str): Method to calculate positions (\"default\", \"centerX\", \"centerY\", \"centerXY\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing positions and class names.\n",
        "    \"\"\"\n",
        "    pos_and_cls = []\n",
        "    result = get_detect_res(img_path)\n",
        "\n",
        "    # Extract bounding boxes and classes\n",
        "    boxes = result[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "    classes = result[0].boxes.cls.cpu().numpy()  # Class indices\n",
        "    names = result[0].names  # Class name mapping\n",
        "\n",
        "    for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
        "        dy = abs(y2 - y1)\n",
        "        dx = abs(x2 - x1)\n",
        "        if method == \"default\":\n",
        "            if dx <= dy:\n",
        "                method = \"centerX\"\n",
        "            else:\n",
        "                method = \"centerXY\"\n",
        "\n",
        "        # Calculate position based on the method\n",
        "        if method == \"centerXY\":\n",
        "            position = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
        "        elif method == \"centerX\":\n",
        "            position = (int((x1 + x2) / 2), int(y2))\n",
        "        elif method == \"centerY\":\n",
        "            position = (int(x2), int((y1 + y2) / 2))\n",
        "\n",
        "\n",
        "        # Get the class name from the index\n",
        "        class_id = int(classes[i])\n",
        "        class_name = names[class_id]\n",
        "\n",
        "        # Add position and class to the result\n",
        "        pos_and_cls.append({\"position\": position, \"class_name\": class_name})\n",
        "\n",
        "    return pos_and_cls\n",
        "\n",
        "def mark_red_dots(img_path):\n",
        "    img = perspective_transform(img_path)\n",
        "    pos_cls = get_transformed_positions_and_classes(img_path, board_pos=False)\n",
        "    for d in pos_cls:\n",
        "        x, y = d[\"position\"]\n",
        "        cv2.circle(img, (int(x), int(y)), 5, (255, 0, 0), -1)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# print(get_positions_and_classes(\"/content/cropped_images/frame_0001.jpg\"))\n",
        "# print(get_transformed_positions_and_classes(\"/content/cropped_images/frame_0001.jpg\"))\n",
        "# mark_red_dots(\"/content/chess-piece--2/train/images/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.e7e6a567661410da0e2ff7b04d785f31.jpg\")"
      ],
      "metadata": {
        "id": "IG-TYuoi7KKs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract img from videos"
      ],
      "metadata": {
        "id": "lvwjyfZXadXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_frames_by_fps(video_path, output_directory, frames_per_second, frame_prefix=\"frame\", start_frame=0):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video at a specified frame rate (frames per second).\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        output_directory (str): Directory to save the extracted frames.\n",
        "        frames_per_second (int): Number of frames to extract per second.\n",
        "        frame_prefix (str): Prefix for the frame filenames (default: \"frame\").\n",
        "        start_frame (int): Starting frame number for naming (default: 0).\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of frames extracted.\n",
        "    \"\"\"\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Cannot open video file {video_path}\")\n",
        "        return 0\n",
        "\n",
        "    # Get video frame rate and total frames\n",
        "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval = int(video_fps // frames_per_second)  # Interval between frames to extract\n",
        "\n",
        "    frame_count = start_frame\n",
        "    frame_index = 0\n",
        "\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    while True:\n",
        "        # Read a frame from the video\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Save only frames at the specified interval\n",
        "        if frame_index % frame_interval == 0:\n",
        "            frame_filename = f\"{output_directory}/{frame_prefix}_{frame_count:04d}.jpg\"\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            print(f\"Saved: {frame_filename}\")\n",
        "            frame_count += 1\n",
        "\n",
        "        frame_index += 1\n",
        "\n",
        "    # Release the video capture object\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"Total frames extracted: {frame_count - start_frame}\")\n",
        "    return frame_count - start_frame\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IcXYAMefKUpK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_black_bar(input_folder, output_folder, size=(640, 640)):\n",
        "    \"\"\"\n",
        "    Processes all images in a folder by removing black borders and resizing them.\n",
        "\n",
        "    Args:\n",
        "        input_folder (str): Path to the folder containing input images.\n",
        "        output_folder (str): Path to the folder to save processed images.\n",
        "        size (tuple): Target size for the resized images (default is 640x640).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        input_path = os.path.join(input_folder, file_name)\n",
        "        output_path = os.path.join(output_folder, file_name)\n",
        "\n",
        "        # Check if the file is an image (optional, based on file extension)\n",
        "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            # Load the image\n",
        "            image = cv2.imread(input_path)\n",
        "            if image is None:\n",
        "                print(f\"Error: Could not load image {file_name}\")\n",
        "                continue\n",
        "\n",
        "            # Convert to grayscale\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Thresholding to create a binary mask\n",
        "            _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            # Find contours to detect the chessboard region\n",
        "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if contours:\n",
        "                # Find the largest contour, assuming it's the chessboard\n",
        "                largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                # Get a bounding rectangle for the largest contour\n",
        "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "                # Crop the image to the bounding rectangle\n",
        "                cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "                # Resize the cropped image to the specified size\n",
        "                resized_image = cv2.resize(cropped_image, size)\n",
        "\n",
        "                # Save the processed image\n",
        "                cv2.imwrite(output_path, resized_image)\n",
        "                print(f\"Processed image saved at: {output_path}\")\n",
        "            else:\n",
        "                print(f\"No contours found in image: {file_name}\")\n",
        "        else:\n",
        "            print(f\"Skipped non-image file: {file_name}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j9YN7wxwBCqA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_hand(img_path, plot=False):\n",
        "    \"\"\"\n",
        "    Detects whether a hand (based on skin tone) is present in the 640x640 image.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if a hand (skin tone) is detected, False otherwise.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    image = perspective_transform(img_path)\n",
        "    if plot:\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "    # Convert the image to HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define HSV range for skin tones (adjust these values as needed)\n",
        "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)  # Lower HSV range\n",
        "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)  # Upper HSV range\n",
        "\n",
        "    # Create a binary mask for skin tones\n",
        "    mask = cv2.inRange(hsv_image, lower_skin, upper_skin)\n",
        "\n",
        "    # Apply morphological operations to reduce noise\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)  # Remove small noise\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Close small holes\n",
        "\n",
        "    # Count non-zero pixels in the mask (skin-colored regions)\n",
        "    skin_pixel_count = cv2.countNonZero(mask)\n",
        "    # Set detection threshold based on 640x640 resolution\n",
        "    detection_threshold = 30000\n",
        "    is_hand_detected = skin_pixel_count > detection_threshold\n",
        "    print(skin_pixel_count)\n",
        "    # Debugging: Uncomment to visualize the mask\n",
        "    # print(\"pixel count =\", skin_pixel_count)\n",
        "    # plt.imshow(mask)\n",
        "    # plt.show()\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "    return is_hand_detected\n",
        "\n",
        "# detect_hand(\"/content/extracted_4_Move_studet/frame_0003.jpg\", plot=True)"
      ],
      "metadata": {
        "id": "kpVaMvClAEen"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_img_frame_folder(video_path):\n",
        "    file_name = video_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    output_directory = \"/content/extracted_\" + file_name\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "    extract_frames_by_fps(video_path, output_directory, 1)\n",
        "    remove_black_bar(output_directory, output_directory)\n",
        "\n",
        "    return output_directory\n",
        "\n",
        "def get_board_pos(x, y):\n",
        "    x_row = \"hgfedcba\"\n",
        "    y_row = \"12345678\"\n",
        "    return x_row[int(x)//80] + y_row[int(y)//80]\n",
        "\n",
        "\n",
        "def convert_board_positions(img_path):\n",
        "    pos_cls = get_transformed_positions_and_classes(img_path, board_pos=False)\n",
        "    new_pos_cls = []\n",
        "    for d in pos_cls:\n",
        "        new_pos_cls.append({\"position\": get_board_pos(d[\"position\"][0], d[\"position\"][1]), \"class_name\": d[\"class_name\"]})\n",
        "    return new_pos_cls\n",
        "\n",
        "def is_valid_img(img_path): #not blocked by hand or can't find 4 corners\n",
        "    if detect_hand(img_path):\n",
        "        print(\"detect hand\")\n",
        "        return False\n",
        "    if len(remove_close_corners(get_corners(find_corners(img_path)))) != 4:\n",
        "        print(\"len(corners) is not 4\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-WAVETGpLzM_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_fen(img_path, active_color='w'):\n",
        "\n",
        "    positions = get_transformed_positions_and_classes(img_path)\n",
        "    # Create an empty board\n",
        "    board = chess.Board.empty()\n",
        "\n",
        "    # Mapping class names to chess symbols\n",
        "    piece_map = {\n",
        "        'white-king': 'K', 'black-king': 'k', 'white-queen': 'Q', 'black-queen': 'q', 'white-rook': 'R', 'black-rook': 'r', 'white-bishop': 'B', 'black-bishop': 'b', 'white-knight': 'N', 'black-knight': 'n', 'white-pawn': 'P', 'black-pawn': 'p'\n",
        "    }\n",
        "    # Place pieces on the board\n",
        "    for item in positions:\n",
        "        position = item['position']\n",
        "        class_name = item['class_name']\n",
        "        piece_symbol = piece_map.get(class_name)\n",
        "        if piece_symbol:\n",
        "            board.set_piece_at(chess.parse_square(position), chess.Piece.from_symbol(piece_symbol))\n",
        "\n",
        "    # Set the active color\n",
        "    board.turn = (active_color == 'w')\n",
        "\n",
        "    # Return the FEN string\n",
        "    return board.fen()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_board(img_path=\"\", board=None):\n",
        "    if img_path != \"\":\n",
        "        fen = generate_fen(img_path)\n",
        "        board = chess.Board(fen)\n",
        "        svg = chess.svg.board(board=board, size=400, orientation=chess.BLACK)\n",
        "        display(SVG(svg))\n",
        "    else:\n",
        "        svg = chess.svg.board(board=board, size=400, orientation=chess.BLACK)\n",
        "        display(SVG(svg))\n",
        "\n",
        "\n",
        "def get_board_diff(previous_frame, current_frame):\n",
        "    \"\"\"\n",
        "    Identifies the differences between two frames by comparing positions and classes.\n",
        "\n",
        "    Args:\n",
        "        previous_frame: The previous frame data.\n",
        "        current_frame: The current frame data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Two lists representing the differences in positions and classes:\n",
        "               - prev_pos: Items present in previous_frame but not in current_frame.\n",
        "               - current_pos: Items present in current_frame but not in previous_frame.\n",
        "    \"\"\"\n",
        "    # Get transformed positions and classes for both frames\n",
        "    prev_pos = get_transformed_positions_and_classes(previous_frame)\n",
        "    current_pos = get_transformed_positions_and_classes(current_frame)\n",
        "\n",
        "    # Convert dictionaries to tuples of sorted key-value pairs for comparison\n",
        "    prev_set = {tuple(sorted(d.items())) for d in prev_pos}\n",
        "    curr_set = {tuple(sorted(d.items())) for d in current_pos}\n",
        "\n",
        "    # Find common items\n",
        "    common_items = prev_set & curr_set\n",
        "\n",
        "    # Filter out common items from the original lists\n",
        "    prev_pos = [d for d in prev_pos if tuple(sorted(d.items())) not in common_items]\n",
        "    current_pos = [d for d in current_pos if tuple(sorted(d.items())) not in common_items]\n",
        "\n",
        "    return prev_pos, current_pos\n",
        "\n",
        "\n",
        "\n",
        "f1 = \"/content/extracted_4_Move_studet/frame_0002.jpg\"\n",
        "f2 = \"/content/extracted_4_Move_studet/frame_0011.jpg\"\n",
        "\n",
        "print(get_board_diff(f1, f2))\n",
        "display_board(img_path = f1)\n",
        "display_board(img_path = f2)"
      ],
      "metadata": {
        "id": "MQoaAILanfD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "outputId": "4b71cae7-d5a0-4edf-87f0-7e6dc3805bf1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "/content/extracted_4_Move_studet/frame_0002.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a359342a476c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/extracted_4_Move_studet/frame_0011.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_board_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mdisplay_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mdisplay_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-a359342a476c>\u001b[0m in \u001b[0;36mget_board_diff\u001b[0;34m(previous_frame, current_frame)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Get transformed positions and classes for both frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprev_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transformed_positions_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mcurrent_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transformed_positions_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2a6dc647200d>\u001b[0m in \u001b[0;36mget_transformed_positions_and_classes\u001b[0;34m(img_path, dst_points, board_pos)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_transformed_positions_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mpos_and_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_positions_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0msrc_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_src_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mret_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-539c00072b45>\u001b[0m in \u001b[0;36mget_positions_and_classes\u001b[0;34m(img_path, method)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m     \u001b[0mpos_and_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_detect_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Extract bounding boxes and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-539c00072b45>\u001b[0m in \u001b[0;36mget_detect_res\u001b[0;34m(img_path, model, plot)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_detect_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchess_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[0;32m--> 257\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/extracted_4_Move_studet/frame_0002.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_move(prev_pos, curr_pos):\n",
        "    san_extended = {\n",
        "    \"black-king\": \"K\",\n",
        "    \"black-queen\": \"Q\",\n",
        "    \"black-rook\": \"R\",\n",
        "    \"black-bishop\": \"B\",\n",
        "    \"black-knight\": \"N\",\n",
        "    \"black-pawn\": \"\",\n",
        "    \"white-king\": \"K\",\n",
        "    \"white-queen\": \"Q\",\n",
        "    \"white-rook\": \"R\",\n",
        "    \"white-bishop\": \"B\",\n",
        "    \"white-knight\": \"N\",\n",
        "    \"white-pawn\": \"\",\n",
        "    }\n",
        "    if len(prev_pos) == 0:\n",
        "        return None\n",
        "    if len(prev_pos) == 1 and len(curr_pos) == 1:\n",
        "        return san_extended[curr_pos[0][\"class_name\"]] + curr_pos[0][\"position\"]\n",
        "    if len(prev_pos) == 2 and len(curr_pos) == 1:\n",
        "        if curr_pos[0][\"position\"] == prev_pos[0][\"position\"]:\n",
        "            return san_extended[curr_pos[0][\"class_name\"]] + curr_pos[0][\"position\"]\n",
        "        else:\n",
        "            return san_extended[prev_pos[1][\"class_name\"]] + prev_pos[1][\"position\"]\n",
        "\n",
        "    print(\"prev_pos\", prev_pos)\n",
        "    print(\"curr_pos\", curr_pos)\n",
        "    if len(prev_pos) != 0 and len(curr_pos) != 0:\n",
        "        return san_extended[curr_pos[0][\"class_name\"]] + curr_pos[0][\"position\"]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def create_PGN(video_path):\n",
        "    folder_path = create_img_frame_folder(video_path)\n",
        "    frames = [os.path.join(folder_path, f) for f in sorted(os.listdir(folder_path)) if f.lower().endswith('.jpg')]\n",
        "    valid_frames = [frame for frame in frames if is_valid_img(frame)]\n",
        "\n",
        "    first_frame = valid_frames[0]\n",
        "\n",
        "\n",
        "    moves = []\n",
        "    for i, frame in enumerate(valid_frames):\n",
        "        if i == 0:\n",
        "            pass\n",
        "        elif i == 1:\n",
        "            pos_before, pos_after = get_board_diff(first_frame, frame)\n",
        "            move = generate_move(pos_before, pos_after)\n",
        "            if move != None:\n",
        "                moves.append(move)\n",
        "        else:\n",
        "            pos_before, pos_after = get_board_diff(valid_frames[i-1], frame)\n",
        "            move = generate_move(pos_before, pos_after)\n",
        "            if move != None:\n",
        "                moves.append(move)\n",
        "\n",
        "    paired_moves = [(moves[i], moves[i+1]) for i in range(0, len(moves) - 1, 2)]\n",
        "    if len(moves) % 2 != 0:\n",
        "        paired_moves.append((moves[-1], \"\"))\n",
        "    string = \"\"\n",
        "    for i in range(len(paired_moves)):\n",
        "        string += str(i+1) + \". \" + paired_moves[i][0] + \" \" + paired_moves[i][1] + \" \"\n",
        "\n",
        "    return string\n",
        "create_PGN(\"/content/4_Move_studet.mp4\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EMoeDIV1vOG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_pgn_from_video(video_path):\n",
        "    \"\"\"\n",
        "    Generates a PGN notation file from image frames in a folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing image frames.\n",
        "        detect_positions_func (function): Function to detect piece positions from an image frame.\n",
        "            It should return a list of dictionaries with 'position' and 'class_name' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: The PGN notation as a string.\n",
        "    \"\"\"\n",
        "    # Get sorted list of image frames\n",
        "    folder_path = create_img_frame_folder(video_path)\n",
        "    frames = [os.path.join(folder_path, f) for f in sorted(os.listdir(folder_path)) if f.lower().endswith('.jpg')]\n",
        "\n",
        "    # Filter out invalid frames\n",
        "    valid_frames = [frame for frame in frames if is_valid_img(frame)]\n",
        "\n",
        "    # Initialize variables\n",
        "    pgn_game = chess.pgn.Game()\n",
        "    node = pgn_game\n",
        "\n",
        "    # Set initial FEN (assuming starting position unless provided)\n",
        "    previous_fen = generate_fen(valid_frames[0], active_color=\"b\")\n",
        "    for frame in valid_frames:\n",
        "\n",
        "        # Generate FEN from detected positions\n",
        "        current_fen = generate_fen(frame)\n",
        "\n",
        "        # Find move between previous and current FEN\n",
        "        move = find_move(previous_fen, current_fen)\n",
        "\n",
        "        # If no move is found, skip to the next frame\n",
        "        if move is None:\n",
        "            print(f\"No valid move found between frames: {previous_fen} -> {current_fen}. Skipping frame.\")\n",
        "            continue\n",
        "        else:\n",
        "            print(\"found move\")\n",
        "\n",
        "        # Add move to PGN\n",
        "        node = node.add_main_variation(chess.Move.from_uci(move))\n",
        "\n",
        "        # Update previous FEN\n",
        "        previous_fen = current_fen\n",
        "\n",
        "    return str(pgn_game)\n",
        "\n",
        "\n",
        "def remove_pgn_headers(pgn):\n",
        "\n",
        "    # Use regex to remove lines starting with `[`\n",
        "    clean_pgn = re.sub(r'^\\[.*\\]\\n', '', pgn, flags=re.MULTILINE)\n",
        "    return clean_pgn\n",
        "\n"
      ],
      "metadata": {
        "id": "H8KLc6B-olN4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}